#! /usr/bin/env python3

import math
import argparse
from collections import defaultdict

def main():
    parser = argparse.ArgumentParser(description="Compare two clusters for similarity",)
    parser.add_argument('-f', '--first', help="First file")
    parser.add_argument('-s', '--second', help="Second file")
    parser.add_argument('-o', '--output', help="File to send output to")

    args = parser.parse_args()

    file1 = args.first
    file2 = args.second
    output = args.output

    dict1 = normalize(defaultdict(int,eval(open(file1, "r").read())))
    dict2 = normalize(defaultdict(int,eval(open(file2, "r").read())))

    n_grams = list(list(dict1.keys()) + list(dict2.keys()))
    numerator = 0
    denom1 = 0
    denom2 = 0

    for n_gram in n_grams:
        numerator += dict1[n_gram] * dict2[n_gram]
        denom1 += dict1[n_gram]**2
        denom2 += dict2[n_gram]**2

    # Somehow we're getting division by zero?  It's post-St. Patrick's party, so
    # let's do the naive way of fixing this.
    if math.sqrt(denom1)*math.sqrt(denom2) == 0:
        denom1 = 0.00001
        denom2 = 0.00001
    print(numerator/(math.sqrt(denom1)*math.sqrt(denom2)))
        
def normalize(vector):
    sum = 0
    for key in vector.keys():
        sum += vector[key]**2
    sum = math.sqrt(sum)
    for key in vector.keys():
        vector[key] = vector[key]/sum
    return vector

if __name__ == "__main__":
    main()
